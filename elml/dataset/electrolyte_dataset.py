import itertools
import json
import random
from typing import Optional, Literal
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

import torch
from torch.utils.data import Dataset

from ..battery import Electrolyte
from ..material import MaterialLibrary
from .. import MLibrary


FeatureMode = Literal["sequence", "weighted_average"]


class ElectrolyteDataset(Dataset):
    """
    ç”µè§£æ¶²æ•°æ®é›†ç®¡ç†å™¨ã€‚
    æ ¸å¿ƒèŒè´£ï¼šåŠ è½½ã€ç®¡ç†ç”µè§£æ¶²é…æ–¹æ•°æ®ï¼Œæä¾›æ•°æ®è®¿é—®æ¥å£ã€‚
    ä¸å…·ä½“æœºå™¨å­¦ä¹ æ¨¡å‹è§£è€¦ï¼Œä¸“æ³¨äºæ•°æ®ç®¡ç†ã€‚
    """

    def __init__(
        self,
        dataset_file: Optional[str] = None,
        feature_mode: FeatureMode = "sequence",
        max_components: int = 10,
        target_metric: str = "conductivity",
    ):
        """
        åˆå§‹åŒ– Dataset ç±»ã€‚

        Args:
            dataset_file (str, optional): é…æ–¹ JSON æ–‡ä»¶è·¯å¾„ã€‚
            feature_mode (FeatureMode): ç‰¹å¾æ¨¡å¼ï¼Œé»˜è®¤ä¸º "sequence"ã€‚
            max_components (int): æ•°æ®é›†ä¸­å¯èƒ½å‡ºç°çš„æœ€å¤§ç»„åˆ†æ•°é‡ï¼Œé»˜è®¤ä¸º 10ã€‚
            target_metric (str): ç›®æ ‡æ€§èƒ½æŒ‡æ ‡ï¼Œé»˜è®¤ä¸º "conductivity"ã€‚
        """

        # PyTorch Dataset çš„æ„é€ å‡½æ•°è°ƒç”¨
        super().__init__()

        self.library: MaterialLibrary = MLibrary
        self.formulas: list[Electrolyte] = []
        self.electrolyte_counter = itertools.count(1)
        self.target_metric = target_metric
        self.feature_mode: FeatureMode = feature_mode
        self.MAX_COMPONENTS = max_components
        self.FEATURE_DIM = (
            3 + 167 + 8 + 1
        )  # ææ–™ç±»å‹(3), åˆ†å­æŒ‡çº¹(167), ç‰©åŒ–æ€§è´¨(8), å æ¯”-Transformeråºåˆ—æ¨¡å‹/æ¸©åº¦-ç®€å•æ¨¡å‹(1) = 179

        # æ¸©åº¦å½’ä¸€åŒ–å‚æ•° (å•ä½ï¼šK)
        # é’ˆå¯¹é”‚ç”µæ± ç”µè§£æ¶²çš„å®ç”¨æ¸©åº¦èŒƒå›´
        self.TEMP_MIN = 223.15  # -50Â°Cï¼ˆä½æ¸©æ€§èƒ½æµ‹è¯•ï¼‰
        self.TEMP_MAX = 373.15  # 100Â°Cï¼ˆé«˜æ¸©æ€§èƒ½æµ‹è¯•ï¼‰

        if dataset_file:
            self.from_json(dataset_file)

    # ------------------------ é­”æœ¯æ–¹æ³• ------------------------ #
    def __len__(self) -> int:
        """è¿”å›æ•°æ®é›†çš„æ ·æœ¬æ€»æ•°"""
        return len(self.formulas)

    # åœ¨ ElectrolyteDataset ç±»å†…éƒ¨
    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        ä½¿æ•°æ®é›†æ”¯æŒä¸‹æ ‡è®¿é—®ã€‚
        ä¸ºæ¨¡å‹è®­ç»ƒæä¾›ä¸€ä¸ªæ ·æœ¬ï¼ŒåŒ…æ‹¬ç‰¹å¾å’Œç›®æ ‡ã€‚
        """
        # 1. æ ¹æ®ç´¢å¼•è·å–åŸå§‹çš„ç”µè§£æ¶²é…æ–¹å¯¹è±¡
        electrolyte: Electrolyte = self.formulas[idx]
        return self._generate_all_tensor(electrolyte)

    def __iter__(self):
        """æ”¯æŒè¿­ä»£è®¿é—®"""
        return iter(self.formulas)

    # ------------------------ æ•°æ®ç®¡ç†æ–¹æ³• ------------------------ #

    def from_json(self, file_path: str):
        """ä» JSON æ–‡ä»¶åŠ è½½é…æ–¹æ•°æ®"""
        with open(file_path, "r", encoding="utf-8") as f:
            formulas_data: list[dict] = json.load(f)

        for data in formulas_data:
            self.add_formula(Electrolyte.from_dict(data))

    def to_json(self, file_path: str):
        """ä¿å­˜é…æ–¹æ•°æ®åˆ° JSON æ–‡ä»¶"""
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump([f.to_dict() for f in self.formulas], f, indent=4)

    def add_formula(self, electrolyte: Electrolyte):
        """æ·»åŠ æ–°é…æ–¹"""
        electrolyte._data.id = f"E{next(self.electrolyte_counter)}"
        self.formulas.append(electrolyte)

    def remove_formula(self, formula_id: str):
        """åˆ é™¤æŒ‡å®š ID çš„é…æ–¹"""
        self.formulas = [f for f in self.formulas if f.id != formula_id]

    def get_formula_by_id(self, formula_id: str) -> Optional[Electrolyte]:
        """æ ¹æ®IDè·å–é…æ–¹"""
        for formula in self.formulas:
            if formula.id == formula_id:
                return formula
        return None

    def update_performance(self, formula_id: str, performance_data: dict):
        """æ›´æ–°æŒ‡å®šé…æ–¹çš„æ€§èƒ½æ•°æ®"""
        formula = self.get_formula_by_id(formula_id)
        if formula:
            formula.performance.update(performance_data)

    # ------------------------ æ•°æ®æŸ¥è¯¢æ–¹æ³• ------------------------ #

    def get_formulas_with_performance(
        self, metric: str = "conductivity"
    ) -> list[Electrolyte]:
        """
        è·å–åŒ…å«æŒ‡å®šæ€§èƒ½æŒ‡æ ‡çš„é…æ–¹åˆ—è¡¨ã€‚
        """
        return [
            f
            for f in self.formulas
            if metric in f.performance and f.performance[metric] is not None
        ]

    def get_formulas_without_performance(
        self, metric: str = "conductivity"
    ) -> list[Electrolyte]:
        """
        è·å–ä¸åŒ…å«æŒ‡å®šæ€§èƒ½æŒ‡æ ‡çš„é…æ–¹åˆ—è¡¨ï¼ˆå¾…é¢„æµ‹æ ·æœ¬ï¼‰ã€‚
        """
        return [
            f
            for f in self.formulas
            if metric not in f.performance or f.performance[metric] is None
        ]

    def filter_formulas(self, filter_func) -> list[Electrolyte]:
        """
        æ ¹æ®è‡ªå®šä¹‰è¿‡æ»¤å‡½æ•°ç­›é€‰é…æ–¹ã€‚

        Args:
            filter_func: æ¥å— Electrolyte å¯¹è±¡å¹¶è¿”å› bool çš„å‡½æ•°
        """
        return [f for f in self.formulas if filter_func(f)]

    def get_performance_statistics(self, metric: str = "conductivity") -> dict:
        """
        è·å–æŒ‡å®šæ€§èƒ½æŒ‡æ ‡çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ã€‚
        """
        values = [
            f.performance[metric]
            for f in self.formulas
            if metric in f.performance and f.performance[metric] is not None
        ]

        if not values:
            return {"count": 0}

        # è½¬æ¢ä¸ºnumpyæ•°ç»„è¿›è¡Œç»Ÿè®¡è®¡ç®—
        values_array = np.array(values)

        # åŸºç¡€ç»Ÿè®¡
        basic_stats = {
            "count": len(values),
            "min": float(values_array.min()),
            "max": float(values_array.max()),
            "mean": float(values_array.mean()),
            "median": float(np.median(values_array)),
            "std": float(values_array.std()),
            "var": float(values_array.var()),
        }

        # åˆ†ä½æ•°ç»Ÿè®¡
        percentiles = {
            "q25": float(np.percentile(values_array, 25)),
            "q75": float(np.percentile(values_array, 75)),
            "q95": float(np.percentile(values_array, 95)),
            "q99": float(np.percentile(values_array, 99)),
        }

        # åˆ†å¸ƒç‰¹å¾
        distribution_stats = {
            "skewness": float(stats.skew(values_array)),
            "kurtosis": float(stats.kurtosis(values_array)),
            "iqr": percentiles["q75"] - percentiles["q25"],
        }

        # å¼‚å¸¸å€¼æ£€æµ‹ (IQRæ–¹æ³•)
        iqr = distribution_stats["iqr"]
        lower_bound = percentiles["q25"] - 1.5 * iqr
        upper_bound = percentiles["q75"] + 1.5 * iqr
        outliers = values_array[
            (values_array < lower_bound) | (values_array > upper_bound)
        ]

        outlier_stats = {
            "outlier_count": len(outliers),
            "outlier_percentage": len(outliers) / len(values) * 100,
            "outlier_values": outliers.tolist(),
            "lower_bound": lower_bound,
            "upper_bound": upper_bound,
        }

        # åˆå¹¶æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯
        return {
            **basic_stats,
            **percentiles,
            **distribution_stats,
            **outlier_stats,
        }

    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰é…æ–¹æ•°æ®"""
        self.formulas.clear()
        self.electrolyte_counter = itertools.count(1)

    def copy(self) -> "ElectrolyteDataset":
        """åˆ›å»ºæ•°æ®é›†çš„æ·±æ‹·è´"""
        new_dataset = ElectrolyteDataset()
        new_dataset.formulas = [f for f in self.formulas]  # æµ…æ‹·è´é…æ–¹åˆ—è¡¨
        return new_dataset

    # ------------------------ æ¸©åº¦å¤„ç†æ–¹æ³• ------------------------ #
    def _normalize_temperature(self, temperature_k: float) -> float:
        """
        å°†æ¸©åº¦æ ‡å‡†åŒ–åˆ° [0, 1] èŒƒå›´

        Args:
            temperature_k (float): æ¸©åº¦å€¼ï¼Œå•ä½ä¸ºå¼€å°”æ–‡(K)

        Returns:
            float: æ ‡å‡†åŒ–åçš„æ¸©åº¦å€¼ [0, 1]
        """
        # é™åˆ¶æ¸©åº¦åœ¨åˆç†èŒƒå›´å†…
        temp_clamped = max(self.TEMP_MIN, min(self.TEMP_MAX, temperature_k))

        # æ ‡å‡†åŒ–åˆ° [0, 1]
        normalized = (temp_clamped - self.TEMP_MIN) / (self.TEMP_MAX - self.TEMP_MIN)

        return normalized

    def get_temperature_statistics(self) -> dict:
        """
        è·å–æ•°æ®é›†ä¸­æ¸©åº¦çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        """
        temperatures = []
        for formula in self.formulas:
            if (
                "temperature" in formula.condition
                and formula.condition["temperature"] is not None
            ):
                temperatures.append(formula.condition["temperature"])

        if not temperatures:
            return {"count": 0}

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        temp_array = np.array(temperatures)

        # åŸºç¡€ç»Ÿè®¡
        basic_stats = {
            "count": len(temperatures),
            "min_k": float(temp_array.min()),
            "max_k": float(temp_array.max()),
            "mean_k": float(temp_array.mean()),
            "median_k": float(np.median(temp_array)),
            "std_k": float(temp_array.std()),
            "min_c": float(temp_array.min()) - 273.15,
            "max_c": float(temp_array.max()) - 273.15,
            "mean_c": float(temp_array.mean()) - 273.15,
            "median_c": float(np.median(temp_array)) - 273.15,
            "std_c": float(temp_array.std()),
        }

        # åˆ†ä½æ•°ç»Ÿè®¡
        percentiles = {
            "q25_k": float(np.percentile(temp_array, 25)),
            "q75_k": float(np.percentile(temp_array, 75)),
            "q95_k": float(np.percentile(temp_array, 95)),
            "q25_c": float(np.percentile(temp_array, 25)) - 273.15,
            "q75_c": float(np.percentile(temp_array, 75)) - 273.15,
            "q95_c": float(np.percentile(temp_array, 95)) - 273.15,
        }

        # åˆ†å¸ƒç‰¹å¾
        distribution_stats = {
            "skewness": float(stats.skew(temp_array)),
            "kurtosis": float(stats.kurtosis(temp_array)),
            "iqr_k": percentiles["q75_k"] - percentiles["q25_k"],
            "iqr_c": percentiles["q75_c"] - percentiles["q25_c"],
        }

        # å½’ä¸€åŒ–ç›¸å…³ä¿¡æ¯
        normalization_stats = {
            "normalization_range": f"{self.TEMP_MIN}K - {self.TEMP_MAX}K",
            "out_of_range_count": sum(
                1 for t in temperatures if t < self.TEMP_MIN or t > self.TEMP_MAX
            ),
            "coverage_percentage": sum(
                1 for t in temperatures if self.TEMP_MIN <= t <= self.TEMP_MAX
            )
            / len(temperatures)
            * 100,
        }

        # æ¸©åº¦åˆ†å¸ƒåŒºé—´ç»Ÿè®¡
        temp_ranges = {
            "very_low_count": sum(1 for t in temperatures if t < 253.15),  # < -20Â°C
            "low_count": sum(
                1 for t in temperatures if 253.15 <= t < 273.15
            ),  # -20Â°C to 0Â°C
            "room_count": sum(
                1 for t in temperatures if 273.15 <= t < 303.15
            ),  # 0Â°C to 30Â°C
            "elevated_count": sum(
                1 for t in temperatures if 303.15 <= t < 333.15
            ),  # 30Â°C to 60Â°C
            "high_count": sum(1 for t in temperatures if t >= 333.15),  # >= 60Â°C
        }

        return {
            **basic_stats,
            **percentiles,
            **distribution_stats,
            **normalization_stats,
            **temp_ranges,
        }

    def validate_temperature_range(self):
        """
        éªŒè¯æ•°æ®é›†ä¸­çš„æ¸©åº¦æ˜¯å¦åœ¨å½’ä¸€åŒ–èŒƒå›´å†…
        """
        temp_stats = self.get_temperature_statistics()

        if temp_stats["count"] == 0:
            print("è­¦å‘Šï¼šæ•°æ®é›†ä¸­æ²¡æœ‰æ¸©åº¦æ•°æ®")
            return

        print("æ¸©åº¦ç»Ÿè®¡ä¿¡æ¯ï¼š")
        print(f"  æ ·æœ¬æ•°é‡: {temp_stats['count']}")
        print(
            f"  æ¸©åº¦èŒƒå›´: {temp_stats['min_k']:.2f}K - {temp_stats['max_k']:.2f}K ({temp_stats['min_c']:.2f}Â°C - {temp_stats['max_c']:.2f}Â°C)"
        )
        print(f"  å½’ä¸€åŒ–èŒƒå›´: {self.TEMP_MIN}K - {self.TEMP_MAX}K")

        if temp_stats["out_of_range_count"] > 0:
            print(
                f"  è­¦å‘Šï¼š{temp_stats['out_of_range_count']} ä¸ªæ ·æœ¬çš„æ¸©åº¦è¶…å‡ºå½’ä¸€åŒ–èŒƒå›´"
            )
        else:
            print("  âœ“ æ‰€æœ‰æ¸©åº¦æ ·æœ¬éƒ½åœ¨å½’ä¸€åŒ–èŒƒå›´å†…")

    def comprehensive_data_analysis(
        self,
        metrics: list[str] = None,
        save_plots: bool = True,
        plot_dir: str = "plots",
    ) -> dict:
        """
        å¯¹æ•°æ®é›†è¿›è¡Œç»¼åˆçš„ç»Ÿè®¡åˆ†æå¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨

        Args:
            metrics: è¦åˆ†æçš„æ€§èƒ½æŒ‡æ ‡åˆ—è¡¨ï¼Œé»˜è®¤ä¸º["conductivity"]
            save_plots: æ˜¯å¦ä¿å­˜å›¾è¡¨åˆ°æ–‡ä»¶
            plot_dir: å›¾è¡¨ä¿å­˜ç›®å½•

        Returns:
            dict: åŒ…å«æ‰€æœ‰åˆ†æç»“æœçš„å­—å…¸
        """
        if metrics is None:
            metrics = ["conductivity"]

        # åˆ›å»ºä¿å­˜ç›®å½•
        if save_plots:
            import os

            os.makedirs(plot_dir, exist_ok=True)

        analysis_results = {}

        # åˆ†ææ¯ä¸ªæ€§èƒ½æŒ‡æ ‡
        for metric in metrics:
            print(f"\n{'=' * 50}")
            print(f"åˆ†ææ€§èƒ½æŒ‡æ ‡: {metric}")
            print(f"{'=' * 50}")

            # è·å–ç»Ÿè®¡ä¿¡æ¯
            perf_stats = self.get_performance_statistics(metric)
            analysis_results[metric] = perf_stats

            if perf_stats["count"] == 0:
                print(f"è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ° {metric} çš„æœ‰æ•ˆæ•°æ®")
                continue

            # æ‰“å°ç»Ÿè®¡æ‘˜è¦
            self._print_performance_summary(metric, perf_stats)

            # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
            if save_plots:
                self._plot_performance_distribution(metric, plot_dir)
                self._plot_performance_boxplot(metric, plot_dir)

        # æ¸©åº¦åˆ†æ
        print(f"\n{'=' * 50}")
        print("æ¸©åº¦æ•°æ®åˆ†æ")
        print(f"{'=' * 50}")

        temp_stats = self.get_temperature_statistics()
        analysis_results["temperature"] = temp_stats

        if temp_stats["count"] > 0:
            self._print_temperature_summary(temp_stats)
            if save_plots:
                self._plot_temperature_distribution(plot_dir)
        else:
            print("è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°æ¸©åº¦æ•°æ®")

        # ç›¸å…³æ€§åˆ†æ
        if len(metrics) > 1:
            print(f"\n{'=' * 50}")
            print("ç›¸å…³æ€§åˆ†æ")
            print(f"{'=' * 50}")
            corr_results = self._analyze_correlations(metrics)
            analysis_results["correlations"] = corr_results
            if save_plots:
                self._plot_correlation_matrix(metrics, plot_dir)

        # æ•°æ®è´¨é‡æŠ¥å‘Š
        print(f"\n{'=' * 50}")
        print("æ•°æ®è´¨é‡æŠ¥å‘Š")
        print(f"{'=' * 50}")
        quality_report = self._generate_quality_report(metrics)
        analysis_results["data_quality"] = quality_report
        self._print_quality_report(quality_report)

        return analysis_results

    def _print_performance_summary(self, metric: str, perf_stats: dict):
        """æ‰“å°æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡æ‘˜è¦"""
        print(f"\nğŸ“Š {metric} ç»Ÿè®¡æ‘˜è¦:")
        print(f"  æ ·æœ¬æ•°é‡: {perf_stats['count']}")
        print(f"  å‡å€¼: {perf_stats['mean']:.4f}")
        print(f"  ä¸­ä½æ•°: {perf_stats['median']:.4f}")
        print(f"  æ ‡å‡†å·®: {perf_stats['std']:.4f}")
        print(f"  æœ€å°å€¼: {perf_stats['min']:.4f}")
        print(f"  æœ€å¤§å€¼: {perf_stats['max']:.4f}")
        print(f"  å››åˆ†ä½è·: {perf_stats['iqr']:.4f}")
        print(f"  ååº¦: {perf_stats['skewness']:.4f}")
        print(f"  å³°åº¦: {perf_stats['kurtosis']:.4f}")
        print(
            f"  å¼‚å¸¸å€¼: {perf_stats['outlier_count']} ({perf_stats['outlier_percentage']:.2f}%)"
        )

    def _print_temperature_summary(self, temp_stats: dict):
        """æ‰“å°æ¸©åº¦ç»Ÿè®¡æ‘˜è¦"""
        print(f"\nğŸŒ¡ï¸ æ¸©åº¦ç»Ÿè®¡æ‘˜è¦:")
        print(f"  æ ·æœ¬æ•°é‡: {temp_stats['count']}")
        print(
            f"  æ¸©åº¦èŒƒå›´: {temp_stats['min_k']:.2f}K - {temp_stats['max_k']:.2f}K ({temp_stats['min_c']:.2f}Â°C - {temp_stats['max_c']:.2f}Â°C)"
        )
        print(f"  å‡å€¼: {temp_stats['mean_k']:.2f}K ({temp_stats['mean_c']:.2f}Â°C)")
        print(
            f"  ä¸­ä½æ•°: {temp_stats['median_k']:.2f}K ({temp_stats['median_c']:.2f}Â°C)"
        )
        print(f"  æ ‡å‡†å·®: {temp_stats['std_k']:.2f}K")
        print(f"  å½’ä¸€åŒ–è¦†ç›–ç‡: {temp_stats['coverage_percentage']:.1f}%")
        print(f"  æ¸©åº¦åˆ†å¸ƒ:")
        print(f"    æä½æ¸©(<-20Â°C): {temp_stats['very_low_count']}")
        print(f"    ä½æ¸©(-20Â°C~0Â°C): {temp_stats['low_count']}")
        print(f"    å®¤æ¸©(0Â°C~30Â°C): {temp_stats['room_count']}")
        print(f"    ä¸­æ¸©(30Â°C~60Â°C): {temp_stats['elevated_count']}")
        print(f"    é«˜æ¸©(â‰¥60Â°C): {temp_stats['high_count']}")

    def _plot_performance_distribution(self, metric: str, plot_dir: str):
        """ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡åˆ†å¸ƒå›¾"""
        values = [
            f.performance[metric]
            for f in self.formulas
            if metric in f.performance and f.performance[metric] is not None
        ]

        if not values:
            return

        plt.figure(figsize=(12, 8))

        # åˆ›å»º2x2å­å›¾
        plt.subplot(2, 2, 1)
        plt.hist(values, bins=30, alpha=0.7, color="skyblue", edgecolor="black")
        plt.title(f"{metric} åˆ†å¸ƒç›´æ–¹å›¾")
        plt.xlabel(metric)
        plt.ylabel("é¢‘æ¬¡")
        plt.grid(True, alpha=0.3)

        plt.subplot(2, 2, 2)
        plt.boxplot(values)
        plt.title(f"{metric} ç®±çº¿å›¾")
        plt.ylabel(metric)
        plt.grid(True, alpha=0.3)

        plt.subplot(2, 2, 3)
        stats.probplot(values, dist="norm", plot=plt)
        plt.title(f"{metric} Q-Qå›¾ (æ­£æ€æ€§æ£€éªŒ)")
        plt.grid(True, alpha=0.3)

        plt.subplot(2, 2, 4)
        sns.violinplot(y=values)
        plt.title(f"{metric} å°æç´å›¾")
        plt.ylabel(metric)

        plt.tight_layout()
        plt.savefig(
            f"{plot_dir}/{metric}_distribution.png", dpi=300, bbox_inches="tight"
        )
        plt.close()

    def _plot_performance_boxplot(self, metric: str, plot_dir: str):
        """ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡è¯¦ç»†ç®±çº¿å›¾"""
        values = [
            f.performance[metric]
            for f in self.formulas
            if metric in f.performance and f.performance[metric] is not None
        ]

        if not values:
            return

        plt.figure(figsize=(10, 6))
        box_plot = plt.boxplot(values, patch_artist=True)
        box_plot["boxes"][0].set_facecolor("lightblue")

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬
        stats_info = self.get_performance_statistics(metric)
        text_info = f"""ç»Ÿè®¡ä¿¡æ¯:
å‡å€¼: {stats_info["mean"]:.4f}
ä¸­ä½æ•°: {stats_info["median"]:.4f}
æ ‡å‡†å·®: {stats_info["std"]:.4f}
å¼‚å¸¸å€¼: {stats_info["outlier_count"]}ä¸ª"""

        plt.text(
            1.1,
            plt.ylim()[1] * 0.8,
            text_info,
            fontsize=10,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="wheat"),
        )

        plt.title(f"{metric} è¯¦ç»†ç®±çº¿å›¾")
        plt.ylabel(metric)
        plt.grid(True, alpha=0.3)
        plt.savefig(f"{plot_dir}/{metric}_boxplot.png", dpi=300, bbox_inches="tight")
        plt.close()

    def _plot_temperature_distribution(self, plot_dir: str):
        """ç»˜åˆ¶æ¸©åº¦åˆ†å¸ƒå›¾"""
        temperatures = []
        for formula in self.formulas:
            if (
                "temperature" in formula.performance
                and formula.performance["temperature"] is not None
            ):
                temperatures.append(formula.performance["temperature"])

        if not temperatures:
            return

        # è½¬æ¢ä¸ºæ‘„æ°åº¦
        temps_c = [t - 273.15 for t in temperatures]

        plt.figure(figsize=(15, 10))

        # 2x3å¸ƒå±€
        plt.subplot(2, 3, 1)
        plt.hist(temps_c, bins=20, alpha=0.7, color="orange", edgecolor="black")
        plt.title("æ¸©åº¦åˆ†å¸ƒç›´æ–¹å›¾")
        plt.xlabel("æ¸©åº¦ (Â°C)")
        plt.ylabel("é¢‘æ¬¡")
        plt.grid(True, alpha=0.3)

        plt.subplot(2, 3, 2)
        plt.boxplot(temps_c)
        plt.title("æ¸©åº¦ç®±çº¿å›¾")
        plt.ylabel("æ¸©åº¦ (Â°C)")
        plt.grid(True, alpha=0.3)

        plt.subplot(2, 3, 3)
        sns.violinplot(y=temps_c)
        plt.title("æ¸©åº¦å°æç´å›¾")
        plt.ylabel("æ¸©åº¦ (Â°C)")

        plt.subplot(2, 3, 4)
        # æ¸©åº¦èŒƒå›´åˆ†å¸ƒé¥¼å›¾
        temp_stats = self.get_temperature_statistics()
        labels = [
            "æä½æ¸©\n(<-20Â°C)",
            "ä½æ¸©\n(-20~0Â°C)",
            "å®¤æ¸©\n(0~30Â°C)",
            "ä¸­æ¸©\n(30~60Â°C)",
            "é«˜æ¸©\n(â‰¥60Â°C)",
        ]
        sizes = [
            temp_stats["very_low_count"],
            temp_stats["low_count"],
            temp_stats["room_count"],
            temp_stats["elevated_count"],
            temp_stats["high_count"],
        ]
        colors = ["lightblue", "lightgreen", "lightyellow", "orange", "lightcoral"]

        # è¿‡æ»¤æ‰ä¸º0çš„éƒ¨åˆ†
        filtered_data = [
            (label, size, color)
            for label, size, color in zip(labels, sizes, colors)
            if size > 0
        ]
        if filtered_data:
            labels, sizes, colors = zip(*filtered_data)
            plt.pie(
                sizes, labels=labels, colors=colors, autopct="%1.1f%%", startangle=90
            )
        plt.title("æ¸©åº¦èŒƒå›´åˆ†å¸ƒ")

        plt.subplot(2, 3, 5)
        # å½’ä¸€åŒ–æ¸©åº¦åˆ†å¸ƒ
        normalized_temps = [self._normalize_temperature(t) for t in temperatures]
        plt.hist(
            normalized_temps, bins=20, alpha=0.7, color="purple", edgecolor="black"
        )
        plt.title("å½’ä¸€åŒ–æ¸©åº¦åˆ†å¸ƒ")
        plt.xlabel("å½’ä¸€åŒ–æ¸©åº¦ [0,1]")
        plt.ylabel("é¢‘æ¬¡")
        plt.grid(True, alpha=0.3)

        plt.subplot(2, 3, 6)
        # æ—¶é—´åºåˆ—å›¾ï¼ˆå¦‚æœæœ‰å¤šä¸ªæ ·æœ¬ï¼‰
        plt.plot(range(len(temps_c)), sorted(temps_c), "o-", markersize=3)
        plt.title("æ¸©åº¦å€¼æ’åºå›¾")
        plt.xlabel("æ ·æœ¬ç´¢å¼•")
        plt.ylabel("æ¸©åº¦ (Â°C)")
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(
            f"{plot_dir}/temperature_analysis.png", dpi=300, bbox_inches="tight"
        )
        plt.close()

    def _analyze_correlations(self, metrics: list[str]) -> dict:
        """åˆ†æä¸åŒæ€§èƒ½æŒ‡æ ‡ä¹‹é—´çš„ç›¸å…³æ€§"""
        correlations = {}

        # è·å–æ‰€æœ‰æŒ‡æ ‡çš„æ•°æ®
        data_matrix = []
        for metric in metrics:
            values = []
            for formula in self.formulas:
                if (
                    metric in formula.performance
                    and formula.performance[metric] is not None
                ):
                    values.append(formula.performance[metric])
                else:
                    values.append(np.nan)
            data_matrix.append(values)

        # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
        data_array = np.array(data_matrix)
        corr_matrix = np.corrcoef(data_array)

        # å­˜å‚¨ç›¸å…³æ€§ç»“æœ
        for i, metric1 in enumerate(metrics):
            correlations[metric1] = {}
            for j, metric2 in enumerate(metrics):
                if i != j:
                    corr_value = corr_matrix[i, j]
                    if not np.isnan(corr_value):
                        correlations[metric1][metric2] = float(corr_value)

        return correlations

    def _plot_correlation_matrix(self, metrics: list[str], plot_dir: str):
        """ç»˜åˆ¶ç›¸å…³æ€§çŸ©é˜µçƒ­å›¾"""
        # æ„å»ºæ•°æ®çŸ©é˜µ
        data_dict = {}
        for metric in metrics:
            data_dict[metric] = []
            for formula in self.formulas:
                if (
                    metric in formula.performance
                    and formula.performance[metric] is not None
                ):
                    data_dict[metric].append(formula.performance[metric])
                else:
                    data_dict[metric].append(np.nan)

        # åˆ›å»ºDataFrame
        import pandas as pd

        df = pd.DataFrame(data_dict)

        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = df.corr()

        plt.figure(figsize=(10, 8))
        sns.heatmap(
            corr_matrix,
            annot=True,
            cmap="coolwarm",
            center=0,
            square=True,
            linewidths=0.5,
        )
        plt.title("æ€§èƒ½æŒ‡æ ‡ç›¸å…³æ€§çŸ©é˜µ")
        plt.tight_layout()
        plt.savefig(f"{plot_dir}/correlation_matrix.png", dpi=300, bbox_inches="tight")
        plt.close()

    def _generate_quality_report(self, metrics: list[str]) -> dict:
        """ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š"""
        total_formulas = len(self.formulas)
        report = {
            "total_samples": total_formulas,
            "metrics_coverage": {},
            "missing_data_summary": {},
            "data_completeness": 0.0,
        }

        total_data_points = 0
        missing_data_points = 0

        for metric in metrics:
            valid_count = len(self.get_formulas_with_performance(metric))
            missing_count = total_formulas - valid_count

            report["metrics_coverage"][metric] = {
                "valid_samples": valid_count,
                "missing_samples": missing_count,
                "coverage_percentage": (valid_count / total_formulas * 100)
                if total_formulas > 0
                else 0,
            }

            total_data_points += total_formulas
            missing_data_points += missing_count

        # åŒ…å«æ¸©åº¦æ•°æ®çš„æ£€æŸ¥
        temp_stats = self.get_temperature_statistics()
        temp_coverage = (
            (temp_stats["count"] / total_formulas * 100) if total_formulas > 0 else 0
        )
        report["metrics_coverage"]["temperature"] = {
            "valid_samples": temp_stats["count"],
            "missing_samples": total_formulas - temp_stats["count"],
            "coverage_percentage": temp_coverage,
        }

        total_data_points += total_formulas
        missing_data_points += total_formulas - temp_stats["count"]

        # è®¡ç®—æ•´ä½“æ•°æ®å®Œæ•´æ€§
        report["data_completeness"] = (
            ((total_data_points - missing_data_points) / total_data_points * 100)
            if total_data_points > 0
            else 0
        )

        return report

    def _print_quality_report(self, report: dict):
        """æ‰“å°æ•°æ®è´¨é‡æŠ¥å‘Š"""
        print(f"\nğŸ“‹ æ•°æ®è´¨é‡æŠ¥å‘Š:")
        print(f"  æ€»æ ·æœ¬æ•°: {report['total_samples']}")
        print(f"  æ•´ä½“æ•°æ®å®Œæ•´æ€§: {report['data_completeness']:.1f}%")
        print(f"\n  å„æŒ‡æ ‡è¦†ç›–æƒ…å†µ:")

        for metric, coverage in report["metrics_coverage"].items():
            print(f"    {metric}:")
            print(f"      æœ‰æ•ˆæ ·æœ¬: {coverage['valid_samples']}")
            print(f"      ç¼ºå¤±æ ·æœ¬: {coverage['missing_samples']}")
            print(f"      è¦†ç›–ç‡: {coverage['coverage_percentage']:.1f}%")

    # ------------------------ ç‰¹å¾æå–æ–¹æ³• ------------------------ #
    def _generate_feature_tensor(
        self, electrolyte: Electrolyte, feature_mode: FeatureMode = "sequence"
    ) -> torch.Tensor:
        """
        æ ¹æ®è®¾å®šçš„æ¨¡å¼ï¼Œä¸ºå•ä¸ªç”µè§£æ¶²å¯¹è±¡ç”Ÿæˆç‰¹å¾å¼ é‡ã€‚
        è¿™æ˜¯æ‰€æœ‰ç‰¹å¾å·¥ç¨‹é€»è¾‘çš„é›†åˆç‚¹ã€‚
        """
        if feature_mode == "sequence":
            # è°ƒç”¨ä¸ºTransformerç­‰åºåˆ—æ¨¡å‹è®¾è®¡çš„ç‰¹å¾ç”Ÿæˆå‡½æ•°
            return self._generate_sequence_features(electrolyte)

        elif feature_mode == "weighted_average":
            # è°ƒç”¨ä¸ºMLP, XGBoostç­‰æ¨¡å‹è®¾è®¡çš„ç‰¹å¾ç”Ÿæˆå‡½æ•°
            return self._generate_average_features(electrolyte)

        else:
            raise ValueError(f"æœªçŸ¥çš„ç‰¹å¾æ¨¡å¼: {feature_mode}")

    def _generate_sequence_features(self, electrolyte: Electrolyte) -> torch.Tensor:
        """
        ä¸ºåºåˆ—æ¨¡å‹ï¼ˆå¦‚Transformerï¼‰ç”Ÿæˆç‰¹å¾å¼ é‡ã€‚
        è¾“å‡ºå½¢çŠ¶ä¸º (MAX_COMPONENTS, FEATURE_DIM+1)
        åˆ†å­æŒ‡çº¹(167), ææ–™ç±»å‹(3), ç‰©åŒ–æ€§è´¨(8), ç»„åˆ†å æ¯”(1) = 179
        [[åˆ†å­æŒ‡çº¹(167), ææ–™ç±»å‹(3), ç‰©åŒ–æ€§è´¨(8), ç»„åˆ†å æ¯”(1)], ...]
        """
        # 1. åˆå§‹åŒ–ä¸€ä¸ªå…¨é›¶çš„å¼ é‡ç”¨äºå¡«å……
        sequence_tensor = torch.zeros(
            self.MAX_COMPONENTS, self.FEATURE_DIM, dtype=torch.float32
        )

        # æ·»åŠ é”‚ç›
        for i, material in enumerate(
            electrolyte.salts + electrolyte.solvents + electrolyte.additives
        ):
            if i >= self.MAX_COMPONENTS:
                print(
                    f"è­¦å‘Šï¼šé…æ–¹ {electrolyte.id} çš„ç»„åˆ†æ•°é‡è¶…è¿‡MAX_COMPONENTSï¼Œéƒ¨åˆ†ç»„åˆ†å°†è¢«å¿½ç•¥ã€‚"
                )
                break

            standardized_features_tensor = torch.tensor(
                material.standardized_feature_values, dtype=torch.float32
            )  # åˆ†å­æŒ‡çº¹(167) + ææ–™ç±»å‹(3) + ç‰©åŒ–æ€§è´¨(8)
            fraction_tensor = torch.tensor(
                [electrolyte.proportions[i] * 0.01], dtype=torch.float32
            )  # ç»„åˆ†å æ¯”(1)

            # å°†ææ–™ç‰¹å¾å’Œå…¶å æ¯”ä¿¡æ¯æ‹¼æ¥åœ¨ä¸€èµ·
            # åˆ†å­æŒ‡çº¹(167), ææ–™ç±»å‹(3), ç‰©åŒ–æ€§è´¨(8), ç»„åˆ†å æ¯”(1)
            final_component_vector = torch.cat(
                [
                    standardized_features_tensor,
                    fraction_tensor,
                ]
            )

            # 3d. å°†æœ€ç»ˆçš„ç»„åˆ†å‘é‡å¡«å…¥åºåˆ—å¼ é‡
            sequence_tensor[i] = final_component_vector

        return sequence_tensor

    def _generate_average_features(self, electrolyte: Electrolyte) -> torch.Tensor:
        """
        é€šè¿‡åŠ æƒå¹³å‡æ³•ç”Ÿæˆä¸€ä¸ªå›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ã€‚
        è¾“å‡ºå½¢çŠ¶ä¸º (FEATURE_DIM,)
        """
        # åˆå§‹åŒ–åŠ æƒå¹³å‡ç‰¹å¾å‘é‡
        weighted_features = torch.zeros(self.FEATURE_DIM - 1, dtype=torch.float32)

        # è·å–æ¸©åº¦ä¿¡æ¯å¹¶æ ‡å‡†åŒ–
        raw_temperature = electrolyte.condition["temperature"]  # å‡è®¾å•ä½ä¸ºK
        normalized_temp = self._normalize_temperature(raw_temperature)
        temperature = torch.tensor([normalized_temp], dtype=torch.float32)

        # è·å–æ‰€æœ‰ç»„åˆ†å’Œå¯¹åº”çš„è´¨é‡å æ¯”
        all_materials = electrolyte.salts + electrolyte.solvents + electrolyte.additives

        for i, material in enumerate(all_materials):
            # è·å–ç»„åˆ†çš„æ ‡å‡†åŒ–ç‰¹å¾
            material_features = torch.tensor(
                material.standardized_feature_values, dtype=torch.float32
            )

            # è·å–ç»„åˆ†çš„è´¨é‡å æ¯”ï¼ˆè½¬æ¢ä¸ºå°æ•°ï¼‰
            weight = electrolyte.proportions[i] * 0.01

            # åŠ æƒç´¯åŠ åˆ°æ€»ç‰¹å¾å‘é‡ï¼Œå¹¶åœ¨æœ€åä¸€ä½è¡¥0
            padded_features = torch.cat([material_features * weight])
            weighted_features += padded_features

        # æœ€åå°†æ¸©åº¦ä¿¡æ¯æ·»åŠ åˆ°ç‰¹å¾å‘é‡ä¸­
        weighted_features_with_tempture = torch.cat([weighted_features, temperature])

        return weighted_features_with_tempture

    def _generate_target_tensor(self, electrolyte: Electrolyte) -> torch.Tensor:
        """
        ä¸ºå•ä¸ªç”µè§£æ¶²å¯¹è±¡ç”Ÿæˆç›®æ ‡å¼ é‡ã€‚
        """
        target_value = electrolyte.performance.get(self.target_metric, 0.0)
        # å¯¹ç›®æ ‡å€¼è¿›è¡Œ log1p å˜æ¢ï¼šlog(1 + Ïƒ)
        # è¿™æ ·å¯ä»¥é¿å…ç”µå¯¼ç‡ä¸º0æ—¶çš„æ•°å­¦é”™è¯¯ï¼ŒåŒæ—¶ä¿æŒæ•°å€¼ç¨³å®šæ€§
        target_value = torch.log1p(torch.tensor(target_value, dtype=torch.float32))
        return target_value

    def _generate_all_tensor(
        self, electrolyte: Electrolyte
    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        ä¸ºå•ä¸ªç”µè§£æ¶²å¯¹è±¡ç”Ÿæˆç‰¹å¾ã€æ¸©åº¦å’Œç›®æ ‡å¼ é‡ã€‚
        """
        # 2. è°ƒç”¨å†…éƒ¨æ–¹æ³•ï¼ŒåŠ¨æ€ç”Ÿæˆè¯¥é…æ–¹çš„ç‰¹å¾å¼ é‡
        feature_tensor = self._generate_feature_tensor(
            electrolyte, feature_mode=self.feature_mode
        )

        # 3. è·å–ç›®æ ‡å€¼ï¼ˆä¾‹å¦‚ç”µå¯¼ç‡ï¼‰ï¼Œå¹¶è½¬æ¢ä¸ºå¼ é‡
        target_tensor = self._generate_target_tensor(electrolyte)

        # è·å–æ¸©åº¦ä¿¡æ¯å¹¶æ ‡å‡†åŒ–
        raw_temperature = electrolyte.condition["temperature"]  # å‡è®¾å•ä½ä¸ºK
        normalized_temp = self._normalize_temperature(raw_temperature)
        temperature = torch.tensor([normalized_temp], dtype=torch.float32)

        return feature_tensor, temperature, target_tensor

    @staticmethod
    def create_splits(
        dataset_file: str,
        feature_mode: FeatureMode = "sequence",
        target_metric: str = "conductivity",
        train_frac: float = 0.8,
        val_frac: float = 0.1,
        random_seed: int = 42,
    ) -> tuple["ElectrolyteDataset", "ElectrolyteDataset", "ElectrolyteDataset"]:
        """
        ä»ä¸€ä¸ªJSONæ–‡ä»¶åˆ›å»ºå¹¶è¿”å›è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•ä¸‰ä¸ªæ•°æ®é›†å®ä¾‹ã€‚

        è¯¥æ–¹æ³•ä¼šè‡ªåŠ¨ç­›é€‰å‡ºåŒ…å«æœ‰æ•ˆæ€§èƒ½æ ‡ç­¾çš„æ ·æœ¬è¿›è¡Œåˆ’åˆ†ã€‚

        Args:
            dataset_file (str): åŒ…å«æ‰€æœ‰é…æ–¹æ•°æ®çš„JSONæ–‡ä»¶è·¯å¾„ã€‚
            feature_mode (str): ä¸ºæ‰€æœ‰æ–°åˆ›å»ºçš„æ•°æ®é›†è®¾ç½®çš„ç‰¹å¾æ¨¡å¼ã€‚
            target_metric (str): ä¸ºæ‰€æœ‰æ–°åˆ›å»ºçš„æ•°æ®é›†è®¾ç½®çš„ç›®æ ‡æ€§èƒ½æŒ‡æ ‡ã€‚
            train_frac (float): è®­ç»ƒé›†æ‰€å æ¯”ä¾‹ã€‚
            val_frac (float): éªŒè¯é›†æ‰€å æ¯”ä¾‹ã€‚æµ‹è¯•é›†æ¯”ä¾‹å°†è‡ªåŠ¨è®¡ç®—ã€‚
            random_seed (int): ç”¨äºå¤ç°éšæœºæ‰“ä¹±ç»“æœçš„ç§å­ã€‚

        Returns:
            tuple: åŒ…å«è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†çš„ä¸‰ä¸ª ElectrolyteDataset å®ä¾‹ã€‚
        """

        # 1. åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ•°æ®é›†å®ä¾‹ä»¥åŠ è½½å’Œç­›é€‰æ•°æ®
        temp_dataset = ElectrolyteDataset(
            dataset_file=dataset_file,
            feature_mode=feature_mode,
            target_metric=target_metric,
        )

        # 2. ç­›é€‰å‡ºæ‰€æœ‰åŒ…å«æœ‰æ•ˆæ€§èƒ½æ ‡ç­¾çš„æ ·æœ¬ï¼Œè¿™æ˜¯æˆ‘ä»¬åˆ’åˆ†çš„åŸºç¡€
        labeled_formulas = temp_dataset.get_formulas_with_performance(
            metric=target_metric
        )

        if not labeled_formulas:
            raise ValueError(
                f"æ•°æ®æ–‡ä»¶ '{dataset_file}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ…å«æ€§èƒ½æŒ‡æ ‡ '{target_metric}' çš„æœ‰æ•ˆæ ·æœ¬ã€‚"
            )

        # 3. ä½¿ç”¨éšæœºç§å­æ¥ä¿è¯æ¯æ¬¡åˆ’åˆ†çš„ç»“æœéƒ½ä¸€æ ·
        random.seed(random_seed)
        random.shuffle(labeled_formulas)

        # 4. è®¡ç®—åˆ‡åˆ†ç‚¹
        n_total = len(labeled_formulas)
        n_train = int(n_total * train_frac)
        n_val = int(n_total * val_frac)

        # 5. åˆ‡åˆ†æ•°æ®åˆ—è¡¨
        train_formulas = labeled_formulas[:n_train]
        val_formulas = labeled_formulas[n_train : n_train + n_val]
        test_formulas = labeled_formulas[n_train + n_val :]

        # 6. åˆ›å»ºä¸‰ä¸ªæ–°çš„ã€é…ç½®æ­£ç¡®çš„æ•°æ®é›†å®ä¾‹
        train_dataset = ElectrolyteDataset(
            target_metric=target_metric, feature_mode=feature_mode
        )
        val_dataset = ElectrolyteDataset(
            target_metric=target_metric, feature_mode=feature_mode
        )
        test_dataset = ElectrolyteDataset(
            target_metric=target_metric, feature_mode=feature_mode
        )

        # 7. å°†åˆ‡åˆ†å¥½çš„é…æ–¹åˆ—è¡¨åˆ†åˆ«èµ‹ç»™æ–°çš„å®ä¾‹
        train_dataset.formulas = train_formulas
        val_dataset.formulas = val_formulas
        test_dataset.formulas = test_formulas

        print(f"æ•°æ®åˆ’åˆ†å®Œæˆ (éšæœºç§å­={random_seed}):")
        print(f"  - è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
        print(f"  - éªŒè¯é›†æ ·æœ¬æ•°: {len(val_dataset)}")
        print(f"  - æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_dataset)}")

        return train_dataset, val_dataset, test_dataset
